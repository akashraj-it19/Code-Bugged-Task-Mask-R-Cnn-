# -*- coding: utf-8 -*-
"""Akashraj(192IT112)_Code-BuggedAI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cRaeWOm0MlnMCrLCVO3HUDqX7hjJjPOF

# **Careers at CODE-BUGGED AI**
Assignment : For Computer Vision Engineer Role

# **Task :-**
Mask R-CNN is an object detection model based on deep convolutional neural networks (CNN)
developed by a group of Facebook AI researchers in 2017. The model can return both the bounding box
and a mask for each detected object in an image.
Prepare a google colab ipynb notebook to implement Mask Rcnn on the custom dataset. In this Assignment following steps should be covered:
 * Data collection and annotation manually.
 * Object Detection with TensorFlow
 * Preparing the Model Configuration Parameters
 * Building the Mask R-CNN Model Architecture
 * Loading the Model Weights
 * Reading an Input Image
 * Detecting Objects
 * Visualizing the Results
 * Complete Code for Prediction
 * Downloading the Training Dataset
 * Preparing the Training Dataset
 * Preparing Model Configuration
 * Training Mask R-CNN in TensorFlow

# **Understanding the Basic Concepts:**
**What is artificial intelligence (AI)?**

Artificial intelligence (AI) is a wide-ranging branch of computer science concerned with building smart machines capable of performing tasks that typically require human intelligence.
Some exapmles of AI are:
 * Siri
 * Alexa etc.. 

Before diving into Mask-Rcnn we will walk into the basics of CNN to understand the Mask-Rcnn Clearly.

**What is a Convolutional Neural Network (CNN)?**

A Convolutional Neural Network (CNN) is a type of artificial neural network used in image recognition and processing that is optimized to process pixel data. Therefore, Convolutional Neural Networks are the fundamental and basic building blocks for the computer vision task of image segmentation.

**What is Mask R-CNN?**

Mask R-CNN, or Mask RCNN, is a Convolutional Neural Network (CNN) and state-of-the-art in terms of image segmentation and instance segmentation. Mask R-CNN was developed on top of Faster R-CNN, a Region-Based Convolutional Neural Network.

**With out any further delat we will dive in to the implementation of mask rcnn with our custom dataset.**

##**STEP 1: PREPARING THE DATASET** 

The sample dataset that I prepared contains a total number of 100 beagle images . I used 75 of them are used for training and 25 of them are used for validation. I used **VGG Image Annotator (VIA)** to annotate the training and validation images. Its a simple tool and it labels all the images and exports it to a single JSON file.

##**Step 2: Install Dependencies**
Fisrt we need to install and downgrade tensorflow to 1.15.0 and keras to 2.2.5 in order to use Matterport's implementation of Mask-RCNN.
"""

!pip install tensorflow-gpu==1.15.0
!pip install keras==2.2.5

"""##**Step 3:Setting up the environment**

Then we clone matterport's implementation of Mask-RCNN and download the pretraind weights trained on COCO dataset. Then , We are going to **" fine - tune the weights using our own dataset ".**
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/matterport/Mask_RCNN.git
# %cd Mask_RCNN/
!python setup.py install
!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5

"""I have also uploaded the dataset that I have to Google Colab. This file also contains the **beagle.py**. I am going to show you the detailed explanation of beagle.py and what is the use of that.


"""

# Commented out IPython magic to ensure Python compatibility.
# %cd fine-tune-MaskRcnn/

"""This shows my current working directory """

!pwd

"""If we are using tensor flow python h5py version should not be more than 2.10.0. So we are setting up with the environment."""

!pip install h5py==2.10.0

"""***After running the above code it is recommended to check the working directory because it asks to restart the run time. If you restart the runtime our data in the root directory will be deleted.***

So , here I am checking what is my current working directory.
"""

!pwd

"""And here I am changing my current working directory for the further implementations. """

# Commented out IPython magic to ensure Python compatibility.
# %cd fine-tune-MaskRcnn

"""**beagle.py**  coontaints seperate classes and functions which is used to configure the model, load the data, train and evaluate the model.Usage of that are \\

    # Train a new model using pre-trained COCO weights
    python3 beagle.py train --dataset=path/to/dataset --weights=coco

    # Resume training a model that you had trained earlier
    python3 beagle.py train --dataset=/path/to/dataset --weights=last

    # Train a new model starting from ImageNet weights
    python3 beagle.py train --dataset=/path/to/dataset --weights=imagenet

    # Apply color splash to an image
    python3 beagle.py splash --weights=/path/to/weights/file.h5 --image=<URL or path to file>

    # Apply color splash to video using the last weights you trained
    python3 beagle.py splash --weights=last --video=<URL or path to file>

Now we are ready to train the model. If you don't have a GPU, you can also use Google Colab. I have only trained the model for 10 epochs, you can modify the number of epochs in beagle.py file.

##**Step 4: Training**
"""

!python3 beagle.py train --dataset=beagle --weights=coco

"""Once the Traning gets completed the weights is stored in the particular folder which you have intialized already..

##**Step 5: Inference using the Trained Model**
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import os
import sys
import random
import math
import re
import time
import numpy as np
import tensorflow as tf
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.patches as patches
ROOT_DIR = os.path.abspath("../")
from mrcnn import utils
from mrcnn import visualize
from mrcnn.visualize import display_images
import mrcnn.model as modellib
from mrcnn.model import log
import beagle
MODEL_DIR = os.path.join(ROOT_DIR, "logs")
MODEL_WEIGHTS_PATH = ROOT_DIR +"/beagle_mask_rcnn_coco.h5"

"""##**Step 6: Setup configurations**"""

config = beagle.CustomConfig()
BEAGLE_DIR = ROOT_DIR+"/fine-tune-MaskRcnn/beagle"

# Override the training configurations with a few
# changes for inferencing.
class InferenceConfig(config.__class__):
    # Run detection on one image at a time
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1

config = InferenceConfig()
config.display()

DEVICE = "/gpu:0"  # /cpu:0 or /gpu:0
def get_ax(rows=1, cols=1, size=16):
    """Return a Matplotlib Axes array to be used in
    all visualizations in the notebook. Provide a
    central point to control graph sizes.
    
    Adjust the size attribute to control how big to render images
    """
    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))
    return ax

"""## **Step 7: Load validation set**"""

dataset = beagle.CustomDataset()
dataset.load_custom(BEAGLE_DIR, "val")

# Must call before using the dataset
dataset.prepare()

print("Images: {}\nClasses: {}".format(len(dataset.image_ids), dataset.class_names))

"""## **Step 8: Create model in inference mode and load our trained weights**"""

# Create model in inference mode
with tf.device(DEVICE):
    model = modellib.MaskRCNN(mode="inference", model_dir=MODEL_DIR,
                              config=config)

weights_path = "/content/logs/beagle20220402T1553/mask_rcnn_beagle_0002.h5"

# Load weights
print("Loading weights ", weights_path)
model.load_weights(weights_path, by_name=True)

"""## **Step 9: Inference on test images**"""

image_id = random.choice(dataset.image_ids)
image, image_meta, gt_class_id, gt_bbox, gt_mask =\
    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)
info = dataset.image_info[image_id]
print("image ID: {}.{} ({}) {}".format(info["source"], info["id"], image_id, 
                                       dataset.image_reference(image_id)))

# Run object detection
results = model.detect([image], verbose=1)

# Display results
ax = get_ax(1)
r = results[0]
visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], 
                            dataset.class_names, r['scores'], ax=ax,
                            title="Predictions")
log("gt_class_id", gt_class_id)
log("gt_bbox", gt_bbox)
log("gt_mask", gt_mask)

image_id = random.choice(dataset.image_ids)
image, image_meta, gt_class_id, gt_bbox, gt_mask =\
    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)
info = dataset.image_info[image_id]
print("image ID: {}.{} ({}) {}".format(info["source"], info["id"], image_id, 
                                       dataset.image_reference(image_id)))

# Run object detection
results = model.detect([image], verbose=1)

# Display results
ax = get_ax(1)
r = results[0]
visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], 
                            dataset.class_names, r['scores'], ax=ax,
                            title="Predictions")
log("gt_class_id", gt_class_id)
log("gt_bbox", gt_bbox)
log("gt_mask", gt_mask)

image_id = random.choice(dataset.image_ids)
image, image_meta, gt_class_id, gt_bbox, gt_mask =\
    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)
info = dataset.image_info[image_id]
print("image ID: {}.{} ({}) {}".format(info["source"], info["id"], image_id, 
                                       dataset.image_reference(image_id)))

# Run object detection
results = model.detect([image], verbose=1)

# Display results
ax = get_ax(1)
r = results[0]
visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], 
                            dataset.class_names, r['scores'], ax=ax,
                            title="Predictions")
log("gt_class_id", gt_class_id)
log("gt_bbox", gt_bbox)
log("gt_mask", gt_mask)

image_id = random.choice(dataset.image_ids)
image, image_meta, gt_class_id, gt_bbox, gt_mask =\
    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)
info = dataset.image_info[image_id]
print("image ID: {}.{} ({}) {}".format(info["source"], info["id"], image_id, 
                                       dataset.image_reference(image_id)))

# Run object detection
results = model.detect([image], verbose=1)

# Display results
ax = get_ax(1)
r = results[0]
visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], 
                            dataset.class_names, r['scores'], ax=ax,
                            title="Predictions")
log("gt_class_id", gt_class_id)
log("gt_bbox", gt_bbox)
log("gt_mask", gt_mask)

image_id = random.choice(dataset.image_ids)
image, image_meta, gt_class_id, gt_bbox, gt_mask =\
    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)
info = dataset.image_info[image_id]
print("image ID: {}.{} ({}) {}".format(info["source"], info["id"], image_id, 
                                       dataset.image_reference(image_id)))

# Run object detection
results = model.detect([image], verbose=1)

# Display results
ax = get_ax(1)
r = results[0]
visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], 
                            dataset.class_names, r['scores'], ax=ax,
                            title="Predictions")
log("gt_class_id", gt_class_id)
log("gt_bbox", gt_bbox)
log("gt_mask", gt_mask)

image_id = random.choice(dataset.image_ids)
image, image_meta, gt_class_id, gt_bbox, gt_mask =\
    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)
info = dataset.image_info[image_id]
print("image ID: {}.{} ({}) {}".format(info["source"], info["id"], image_id, 
                                       dataset.image_reference(image_id)))

# Run object detection
results = model.detect([image], verbose=1)

# Display results
ax = get_ax(1)
r = results[0]
visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], 
                            dataset.class_names, r['scores'], ax=ax,
                            title="Predictions")
log("gt_class_id", gt_class_id)
log("gt_bbox", gt_bbox)
log("gt_mask", gt_mask)

image_id = random.choice(dataset.image_ids)
image, image_meta, gt_class_id, gt_bbox, gt_mask =\
    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)
info = dataset.image_info[image_id]
print("image ID: {}.{} ({}) {}".format(info["source"], info["id"], image_id, 
                                       dataset.image_reference(image_id)))

# Run object detection
results = model.detect([image], verbose=1)

# Display results
ax = get_ax(1)
r = results[0]
visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], 
                            dataset.class_names, r['scores'], ax=ax,
                            title="Predictions")
log("gt_class_id", gt_class_id)
log("gt_bbox", gt_bbox)
log("gt_mask", gt_mask)

image_id = random.choice(dataset.image_ids)
image, image_meta, gt_class_id, gt_bbox, gt_mask =\
    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)
info = dataset.image_info[image_id]
print("image ID: {}.{} ({}) {}".format(info["source"], info["id"], image_id, 
                                       dataset.image_reference(image_id)))

# Run object detection
results = model.detect([image], verbose=1)

# Display results
ax = get_ax(1)
r = results[0]
visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], 
                            dataset.class_names, r['scores'], ax=ax,
                            title="Predictions")
log("gt_class_id", gt_class_id)
log("gt_bbox", gt_bbox)
log("gt_mask", gt_mask)

image_id = random.choice(dataset.image_ids)
image, image_meta, gt_class_id, gt_bbox, gt_mask =\
    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)
info = dataset.image_info[image_id]
print("image ID: {}.{} ({}) {}".format(info["source"], info["id"], image_id, 
                                       dataset.image_reference(image_id)))

# Run object detection
results = model.detect([image], verbose=1)

# Display results
ax = get_ax(1)
r = results[0]
visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], 
                            dataset.class_names, r['scores'], ax=ax,
                            title="Predictions")
log("gt_class_id", gt_class_id)
log("gt_bbox", gt_bbox)
log("gt_mask", gt_mask)

image_id = random.choice(dataset.image_ids)
image, image_meta, gt_class_id, gt_bbox, gt_mask =\
    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)
info = dataset.image_info[image_id]
print("image ID: {}.{} ({}) {}".format(info["source"], info["id"], image_id, 
                                       dataset.image_reference(image_id)))

# Run object detection
results = model.detect([image], verbose=1)

# Display results
ax = get_ax(1)
r = results[0]
visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], 
                            dataset.class_names, r['scores'], ax=ax,
                            title="Predictions")
log("gt_class_id", gt_class_id)
log("gt_bbox", gt_bbox)
log("gt_mask", gt_mask)

"""## **Summary**
we have learned  how to fine-tune a custom Mask-RCNN model on our own  prepared Beagle dataset. I have cleared demonstrated the entire training process, from preparing the dataset to how to perform inference using your own model.

---

That's It. Thank you for giving me this wonderful opportunity to present ...!!

"""